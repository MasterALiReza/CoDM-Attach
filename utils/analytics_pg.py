"""
Ù…Ø§Ú˜ÙˆÙ„ Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ù…Ø§Ø± Ùˆ ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø¬Ø¨Ø§Ø±ÛŒ - PostgreSQL Backend
Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† analytics.py Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ø§Ø² PostgreSQL Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""

import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import logging

logger = logging.getLogger(__name__)


class AnalyticsPostgres:
    """Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ù…Ø§Ø± Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø§ PostgreSQL Backend"""
    
    def __init__(self, database_url: str = None, db_adapter=None):
        """
        Args:
            database_url: PostgreSQL connection string (Ø§Ø®ØªÛŒØ§Ø±ÛŒ - Ø§Ø² env Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯)
        """
        # Use central DatabaseAdapter (singleton) unless provided
        if db_adapter is None:
            try:
                from core.database.database_adapter import get_database_adapter
                self.db = get_database_adapter()
            except Exception as e:
                raise ValueError(f"Database adapter not available: {e}")
        else:
            self.db = db_adapter

        # Backward-compat: keep attribute but not used directly
        self.database_url = database_url or os.getenv('DATABASE_URL')

        # Ensure schema exists (self-healing) for analytics tables via pooled connection
        try:
            self._ensure_schema()
        except Exception as e:
            logger.warning(f"Could not ensure analytics schema: {e}")
        logger.info("AnalyticsPostgres initialized")
    
    def _get_connection(self):
        """Ø¯Ø±ÛŒØ§ÙØª connection Ø¨Ù‡ PostgreSQL"""
        # Delegate to adapter's pooled connection
        return self.db.get_connection()
    
    def _ensure_schema(self) -> None:
        """Ensure required tables for analytics exist."""
        with self._get_connection() as conn:
            cur = conn.cursor()
            # analytics_users
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS analytics_users (
                    user_id BIGINT PRIMARY KEY,
                    first_seen TIMESTAMP NOT NULL DEFAULT NOW(),
                    join_attempts INTEGER NOT NULL DEFAULT 0,
                    completed BOOLEAN NOT NULL DEFAULT FALSE,
                    channels_joined JSONB
                );
                """
            )
            # analytics_channels
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS analytics_channels (
                    channel_id TEXT PRIMARY KEY,
                    title TEXT,
                    url TEXT,
                    added_at TIMESTAMP NOT NULL DEFAULT NOW(),
                    removed_at TIMESTAMP,
                    status TEXT NOT NULL DEFAULT 'active',
                    total_joins INTEGER NOT NULL DEFAULT 0,
                    total_join_attempts INTEGER NOT NULL DEFAULT 0,
                    conversion_rate NUMERIC NOT NULL DEFAULT 0,
                    changes JSONB
                );
                """
            )
            # analytics_daily_stats
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS analytics_daily_stats (
                    date DATE PRIMARY KEY,
                    new_users INTEGER NOT NULL DEFAULT 0,
                    successful_joins INTEGER NOT NULL DEFAULT 0,
                    failed_joins INTEGER NOT NULL DEFAULT 0,
                    total_attempts INTEGER NOT NULL DEFAULT 0,
                    conversion_rate NUMERIC NOT NULL DEFAULT 0
                );
                """
            )
            conn.commit()
    
    def _get_today_key(self) -> str:
        """Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯ Ø§Ù…Ø±ÙˆØ² Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡"""
        return datetime.now().strftime("%Y-%m-%d")
    
    def _ensure_daily_stats(self, cursor, date_key: str):
        """Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø³Ø§Ø®ØªØ§Ø± Ø¢Ù…Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡"""
        cursor.execute("""
            INSERT INTO analytics_daily_stats (date)
            VALUES (%s)
            ON CONFLICT (date) DO NOTHING
        """, (date_key,))
    
    # ===== User Tracking =====
    
    def track_user_start(self, user_id: int) -> bool:
        """Ø«Ø¨Øª Ø§ÙˆÙ„ÛŒÙ† ÙˆØ±ÙˆØ¯ Ú©Ø§Ø±Ø¨Ø± Ø¨Ù‡ Ø±Ø¨Ø§Øª"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯ Ø§Ø³Øª
                cursor.execute("""
                    INSERT INTO analytics_users (user_id, first_seen)
                    VALUES (%s, %s)
                    ON CONFLICT (user_id) DO NOTHING
                    RETURNING user_id
                """, (user_id, datetime.now()))
                
                is_new = cursor.fetchone() is not None
                
                if is_new:
                    # Ø¢Ù…Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡
                    today = self._get_today_key()
                    self._ensure_daily_stats(cursor, today)
                    cursor.execute("""
                        UPDATE analytics_daily_stats
                        SET new_users = new_users + 1
                        WHERE date = %s
                    """, (today,))
                    
                    logger.info(f"[Analytics] New user tracked: {user_id}")
                
                conn.commit()
                cursor.close()
                return True
                
        except Exception as e:
            logger.error(f"[Analytics] Error tracking user start: {e}")
            return False
    
    def track_join_attempt(self, user_id: int, channel_id: str) -> bool:
        """Ø«Ø¨Øª ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¹Ø¶ÙˆÛŒØª (Ø²Ø¯Ù† Ø¯Ú©Ù…Ù‡ Ø¹Ø¶Ùˆ Ø´Ø¯Ù…)"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ú©Ø§Ø±Ø¨Ø±
                cursor.execute("""
                    INSERT INTO analytics_users (user_id, first_seen)
                    VALUES (%s, %s)
                    ON CONFLICT (user_id) DO NOTHING
                """, (user_id, datetime.now()))
                
                # Ø§ÙØ²Ø§ÛŒØ´ ØªØ¹Ø¯Ø§Ø¯ ØªÙ„Ø§Ø´â€ŒÙ‡Ø§
                cursor.execute("""
                    UPDATE analytics_users
                    SET join_attempts = join_attempts + 1,
                        channels_joined = jsonb_set(
                            COALESCE(channels_joined, '{}'::jsonb),
                            ARRAY[%s],
                            jsonb_build_object(
                                'joined_at', NULL,
                                'attempts', COALESCE((channels_joined->%s->>'attempts')::int, 0) + 1
                            ),
                            true
                        )
                    WHERE user_id = %s
                """, (channel_id, channel_id, user_id))
                
                # Ø¢Ù…Ø§Ø± Ú©Ø§Ù†Ø§Ù„
                cursor.execute("""
                    UPDATE analytics_channels
                    SET total_join_attempts = total_join_attempts + 1
                    WHERE channel_id = %s
                """, (channel_id,))
                
                # Ø¢Ù…Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡
                today = self._get_today_key()
                self._ensure_daily_stats(cursor, today)
                cursor.execute("""
                    UPDATE analytics_daily_stats
                    SET total_attempts = total_attempts + 1
                    WHERE date = %s
                """, (today,))
                
                conn.commit()
                cursor.close()
                logger.info(f"[Analytics] Join attempt: user={user_id}, channel={channel_id}")
                return True
                
        except Exception as e:
            logger.error(f"[Analytics] Error tracking join attempt: {e}")
            return False
    
    def track_join_success(self, user_id: int, channel_id: str) -> bool:
        """Ø«Ø¨Øª Ø¹Ø¶ÙˆÛŒØª Ù…ÙˆÙÙ‚ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ú©Ø§Ø±Ø¨Ø±
                cursor.execute("""
                    INSERT INTO analytics_users (user_id, first_seen)
                    VALUES (%s, %s)
                    ON CONFLICT (user_id) DO NOTHING
                """, (user_id, datetime.now()))
                
                # Ø«Ø¨Øª Ø²Ù…Ø§Ù† Ø¹Ø¶ÙˆÛŒØª Ù…ÙˆÙÙ‚
                cursor.execute("""
                    UPDATE analytics_users
                    SET channels_joined = jsonb_set(
                        COALESCE(channels_joined, '{}'::jsonb),
                        ARRAY[%s, 'joined_at'],
                        to_jsonb(%s::text),
                        true
                    )
                    WHERE user_id = %s
                """, (channel_id, datetime.now().isoformat(), user_id))
                
                # Ú†Ú© Ú©Ø±Ø¯Ù† completion (Ù‡Ù…Ù‡ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ Ø±Ø§ join Ú©Ø±Ø¯Ù‡ØŸ)
                cursor.execute("""
                    SELECT COUNT(*) as active_count
                    FROM analytics_channels
                    WHERE status = 'active'
                """)
                _row = cursor.fetchone()
                active_count = int((_row or {}).get('active_count') or 0)
                
                cursor.execute("""
                    SELECT jsonb_object_keys(channels_joined) as channel_id
                    FROM analytics_users
                    WHERE user_id = %s
                """, (user_id,))
                joined_channels = [row['channel_id'] for row in cursor.fetchall()]
                
                # Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ active Ú©Ù‡ join Ø´Ø¯Ù‡
                cursor.execute("""
                    SELECT COUNT(*) as joined_active
                    FROM analytics_channels
                    WHERE status = 'active' 
                    AND channel_id = ANY(%s)
                """, (joined_channels,))
                _row2 = cursor.fetchone()
                joined_active_count = int((_row2 or {}).get('joined_active') or 0)
                
                if joined_active_count >= active_count and active_count > 0:
                    cursor.execute("""
                        UPDATE analytics_users
                        SET completed = TRUE
                        WHERE user_id = %s
                    """, (user_id,))
                
                # Ø¢Ù…Ø§Ø± Ú©Ø§Ù†Ø§Ù„
                cursor.execute("""
                    UPDATE analytics_channels
                    SET total_joins = total_joins + 1,
                        conversion_rate = CASE 
                            WHEN total_join_attempts > 0 
                            THEN ROUND(((total_joins + 1)::numeric / total_join_attempts::numeric) * 100, 2)
                            ELSE 0.0
                        END
                    WHERE channel_id = %s
                """, (channel_id,))
                
                # Ø¢Ù…Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡
                today = self._get_today_key()
                self._ensure_daily_stats(cursor, today)
                cursor.execute("""
                    UPDATE analytics_daily_stats
                    SET successful_joins = successful_joins + 1,
                        conversion_rate = CASE
                            WHEN total_attempts > 0
                            THEN ROUND(((successful_joins + 1)::numeric / total_attempts::numeric) * 100, 2)
                            ELSE 0.0
                        END
                    WHERE date = %s
                """, (today,))
                
                conn.commit()
                cursor.close()
                logger.info(f"[Analytics] Join success: user={user_id}, channel={channel_id}")
                return True
                
        except Exception as e:
            logger.error(f"[Analytics] Error tracking join success: {e}")
            return False
    
    # ===== Channel Management Tracking =====
    
    def track_channel_added(self, channel_id: str, title: str, url: str, admin_id: int) -> bool:
        """Ø«Ø¨Øª Ø§ÙØ²ÙˆØ¯Ù† Ú©Ø§Ù†Ø§Ù„ Ø¬Ø¯ÛŒØ¯"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                changes = [{
                    "timestamp": datetime.now().isoformat(),
                    "action": "added",
                    "admin_id": admin_id
                }]
                
                cursor.execute("""
                    INSERT INTO analytics_channels 
                    (channel_id, title, url, added_at, status, changes)
                    VALUES (%s, %s, %s, %s, %s, %s)
                    ON CONFLICT (channel_id) DO UPDATE SET
                        title = EXCLUDED.title,
                        url = EXCLUDED.url,
                        status = 'active'
                """, (channel_id, title, url, datetime.now(), 'active', json.dumps(changes)))
                
                conn.commit()
                cursor.close()
                logger.info(f"[Analytics] Channel added: {channel_id} by admin {admin_id}")
                return True
                
        except Exception as e:
            logger.error(f"[Analytics] Error tracking channel added: {e}")
            return False
    
    def track_channel_removed(self, channel_id: str, admin_id: int) -> bool:
        """Ø«Ø¨Øª Ø­Ø°Ù Ú©Ø§Ù†Ø§Ù„"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                cursor.execute("""
                    UPDATE analytics_channels
                    SET removed_at = %s,
                        status = 'removed',
                        changes = changes || %s::jsonb
                    WHERE channel_id = %s
                """, (
                    datetime.now(),
                    json.dumps([{
                        "timestamp": datetime.now().isoformat(),
                        "action": "removed",
                        "admin_id": admin_id
                    }]),
                    channel_id
                ))
                
                conn.commit()
                cursor.close()
                logger.info(f"[Analytics] Channel removed: {channel_id} by admin {admin_id}")
                return True
                
        except Exception as e:
            logger.error(f"[Analytics] Error tracking channel removed: {e}")
            return False
    
    def track_channel_updated(self, channel_id: str, admin_id: int, 
                             title: str = None, url: str = None) -> bool:
        """Ø«Ø¨Øª ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ø§Ù†Ø§Ù„"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                
                changes_list = []
                update_fields = []
                params = []
                
                if title:
                    update_fields.append("title = %s")
                    params.append(title)
                    changes_list.append(f"title: {title}")
                
                if url:
                    update_fields.append("url = %s")
                    params.append(url)
                    changes_list.append(f"url: {url}")
                
                if changes_list:
                    change_entry = {
                        "timestamp": datetime.now().isoformat(),
                        "action": "updated",
                        "admin_id": admin_id,
                        "changes": ", ".join(changes_list)
                    }
                    
                    update_fields.append("changes = changes || %s::jsonb")
                    params.append(json.dumps([change_entry]))
                    params.append(channel_id)
                    
                    query = f"UPDATE analytics_channels SET {', '.join(update_fields)} WHERE channel_id = %s"
                    cursor.execute(query, params)
                    
                    conn.commit()
                    logger.info(f"[Analytics] Channel updated: {channel_id} by admin {admin_id}")
                
                cursor.close()
                return True
                
        except Exception as e:
            logger.error(f"[Analytics] Error tracking channel updated: {e}")
            return False
    
    # ===== Get Statistics =====
    
    def get_channel_stats(self, channel_id: str) -> Optional[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± ÛŒÚ© Ú©Ø§Ù†Ø§Ù„"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM analytics_channels WHERE channel_id = %s
                """, (channel_id,))
                
                row = cursor.fetchone()
                cursor.close()
                
                if row:
                    return dict(row)
                return None
                
        except Exception as e:
            logger.error(f"[Analytics] Error getting channel stats: {e}")
            return None
    
    def get_all_channels_stats(self) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ù‡Ù…Ù‡ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT * FROM analytics_channels ORDER BY added_at DESC")
                
                rows = cursor.fetchall()
                cursor.close()
                
                return [dict(r) for r in rows]
                
        except Exception as e:
            logger.error(f"[Analytics] Error getting all channels: {e}")
            return []
    
    def get_active_channels_stats(self) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM analytics_channels 
                    WHERE status = 'active' 
                    ORDER BY added_at DESC
                """)
                
                rows = cursor.fetchall()
                cursor.close()
                
                return [dict(r) for r in rows]
                
        except Exception as e:
            logger.error(f"[Analytics] Error getting active channels: {e}")
            return []
    
    def get_removed_channels_stats(self) -> List[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM analytics_channels 
                    WHERE status = 'removed' 
                    ORDER BY removed_at DESC
                """)
                
                rows = cursor.fetchall()
                cursor.close()
                
                return [dict(r) for r in rows]
                
        except Exception as e:
            logger.error(f"[Analytics] Error getting removed channels: {e}")
            return []
    
    def get_daily_stats(self, date_key: str = None) -> Dict:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡"""
        if date_key is None:
            date_key = self._get_today_key()
        
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                self._ensure_daily_stats(cursor, date_key)
                
                cursor.execute("""
                    SELECT * FROM analytics_daily_stats WHERE date = %s
                """, (date_key,))
                
                row = cursor.fetchone()
                conn.commit()
                cursor.close()
                
                if row:
                    return dict(row)
                return {}
                
        except Exception as e:
            logger.error(f"[Analytics] Error getting daily stats: {e}")
            return {}
    
    def get_user_stats(self, user_id: int) -> Optional[Dict]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± ÛŒÚ© Ú©Ø§Ø±Ø¨Ø±"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT * FROM analytics_users WHERE user_id = %s
                """, (user_id,))
                
                row = cursor.fetchone()
                cursor.close()
                
                if row:
                    result = dict(row)
                    # ØªØ¨Ø¯ÛŒÙ„ JSONB Ø¨Ù‡ dict
                    if 'channels_joined' in result and result['channels_joined']:
                        result['channels_joined'] = json.loads(result['channels_joined']) if isinstance(result['channels_joined'], str) else result['channels_joined']
                    return result
                return None
                
        except Exception as e:
            logger.error(f"[Analytics] Error getting user stats: {e}")
            return None
    
    def get_total_users(self) -> int:
        """Ø¯Ø±ÛŒØ§ÙØª ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) AS count FROM analytics_users")
                row = cursor.fetchone()
                count = int(row.get('count') or 0) if row else 0
                cursor.close()
                return count
        except Exception as e:
            logger.error(f"[Analytics] Error getting total users: {e}")
            return 0
    
    def get_completed_users(self) -> int:
        """Ø¯Ø±ÛŒØ§ÙØª ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†ÛŒ Ú©Ù‡ Ù‡Ù…Ù‡ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø±Ø§ join Ú©Ø±Ø¯Ù†Ø¯"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) AS count FROM analytics_users WHERE completed = TRUE")
                row = cursor.fetchone()
                count = int(row.get('count') or 0) if row else 0
                cursor.close()
                return count
        except Exception as e:
            logger.error(f"[Analytics] Error getting completed users: {e}")
            return 0
    
    # ===== Dashboard Generation =====
    
    def generate_admin_dashboard(self) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ dashboard Ù…ØªÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¯Ù…ÛŒÙ†"""
        try:
            lines = []
            lines.append("ğŸ“Š <b>Ø¢Ù…Ø§Ø± Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø¬Ø¨Ø§Ø±ÛŒ</b>\n")
            
            # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
            total_users = self.get_total_users()
            completed_users = self.get_completed_users()
            
            lines.append(f"ğŸ‘¥ Ú©Ù„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: <b>{total_users}</b>")
            if total_users > 0:
                completion_rate = round((completed_users / total_users) * 100, 1)
                lines.append(f"âœ… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡: <b>{completed_users}</b> ({completion_rate}%)")
                lines.append(f"âŒ Ù†Ø§ØªÙ…Ø§Ù…: <b>{total_users - completed_users}</b>\n")
            else:
                lines.append("âœ… ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡: <b>0</b>")
                lines.append("âŒ Ù†Ø§ØªÙ…Ø§Ù…: <b>0</b>\n")
            
            # Ø¢Ù…Ø§Ø± Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„
            active_channels = self.get_active_channels_stats()
            removed_channels = self.get_removed_channels_stats()
            
            lines.append(f"ğŸŸ¢ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„: <b>{len(active_channels)}</b>")
            lines.append(f"ğŸ”´ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡: <b>{len(removed_channels)}</b>\n")
            
            # Ø¬Ø²Ø¦ÛŒØ§Øª Ù‡Ø± Ú©Ø§Ù†Ø§Ù„ ÙØ¹Ø§Ù„
            if active_channels:
                lines.append("ğŸ“¢ <b>Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„:</b>\n")
                for i, channel in enumerate(active_channels[:5], 1):  # ÙÙ‚Ø· 5 ØªØ§ Ø§ÙˆÙ„
                    title = channel.get("title", "Unknown")
                    joins = channel.get("total_joins", 0)
                    attempts = channel.get("total_join_attempts", 0)
                    conv_rate = channel.get("conversion_rate", 0.0)
                    
                    lines.append(f"{i}. <b>{title}</b>")
                    lines.append(f"   â€¢ Ø¹Ø¶Ùˆ Ø´Ø¯Ù‡: {joins} Ù†ÙØ±")
                    lines.append(f"   â€¢ ØªÙ„Ø§Ø´: {attempts} Ø¨Ø§Ø±")
                    lines.append(f"   â€¢ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„: {conv_rate}%\n")
            
            # Ø¢Ù…Ø§Ø± Ø§Ù…Ø±ÙˆØ²
            today_stats = self.get_daily_stats()
            if today_stats.get("new_users", 0) > 0 or today_stats.get("successful_joins", 0) > 0:
                lines.append("ğŸ“… <b>Ø¢Ù…Ø§Ø± Ø§Ù…Ø±ÙˆØ²:</b>")
                lines.append(f"   â€¢ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¬Ø¯ÛŒØ¯: {today_stats.get('new_users', 0)}")
                lines.append(f"   â€¢ Ø¹Ø¶ÙˆÛŒØª Ù…ÙˆÙÙ‚: {today_stats.get('successful_joins', 0)}")
                lines.append(f"   â€¢ Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„: {today_stats.get('conversion_rate', 0)}%")
            
            return "\n".join(lines)
            
        except Exception as e:
            logger.error(f"[Analytics] Error generating dashboard: {e}")
            return "âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ dashboard"
    
    def generate_channel_history_report(self) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡ (PostgreSQL)"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    SELECT title, total_joins, added_at, removed_at
                    FROM analytics_channels
                    WHERE status = 'removed'
                    ORDER BY removed_at DESC NULLS LAST
                    """
                )
                rows = cursor.fetchall()
                cursor.close()
                removed_channels = [dict(row) for row in rows]
        except Exception as e:
            logger.error(f"[Analytics] Error generating history report: {e}")
            removed_channels = []

        if not removed_channels:
            return "ğŸ“‹ <b>ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡</b>\n\nÙ‡ÛŒÚ† Ú©Ø§Ù†Ø§Ù„ Ø­Ø°Ù Ø´Ø¯Ù‡â€ŒØ§ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."

        lines = []
        lines.append("ğŸ“‹ <b>ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡</b>\n")
        for i, ch in enumerate(removed_channels, 1):
            title = ch.get("title", "Unknown")
            joins = ch.get("total_joins", 0)
            added_at = ch.get("added_at")
            removed_at = ch.get("removed_at")
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¯Øª ÙØ¹Ø§Ù„ÛŒØª
            try:
                from datetime import datetime as _dt
                if added_at and removed_at:
                    if not isinstance(added_at, _dt):
                        added_at = _dt.fromisoformat(str(added_at))
                    if not isinstance(removed_at, _dt):
                        removed_at = _dt.fromisoformat(str(removed_at))
                    duration_days = (removed_at - added_at).days
                    duration_str = f"{duration_days} Ø±ÙˆØ²"
                else:
                    duration_str = "Ù†Ø§Ù…Ø´Ø®Øµ"
            except Exception:
                duration_str = "Ù†Ø§Ù…Ø´Ø®Øµ"

            lines.append(f"{i}. <b>{title}</b>")
            lines.append(f"   â€¢ Ú©Ù„ Ø§Ø¹Ø¶Ø§: {joins} Ù†ÙØ±")
            lines.append(f"   â€¢ Ù…Ø¯Øª ÙØ¹Ø§Ù„ÛŒØª: {duration_str}")
            lines.append(
                f"   â€¢ Ø­Ø°Ù Ø´Ø¯Ù‡: {str(removed_at)[:10] if removed_at else 'Ù†Ø§Ù…Ø´Ø®Øµ'}\n"
            )

        return "\n".join(lines)

    def generate_funnel_analysis(self) -> str:
        """ØªØ­Ù„ÛŒÙ„ Ù‚ÛŒÙ ØªØ¨Ø¯ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† (PostgreSQL)"""
        try:
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) AS count FROM analytics_users")
                row = cursor.fetchone(); started = int(row.get('count') or 0) if row else 0
                cursor.execute("SELECT COUNT(*) AS count FROM analytics_users WHERE join_attempts > 0")
                row = cursor.fetchone(); attempted = int(row.get('count') or 0) if row else 0
                cursor.execute("SELECT COUNT(*) AS count FROM analytics_users WHERE completed = TRUE")
                row = cursor.fetchone(); completed = int(row.get('count') or 0) if row else 0
                cursor.close()
        except Exception as e:
            logger.error(f"[Analytics] Error generating funnel: {e}")
            started = attempted = completed = 0

        if started == 0:
            return "ğŸ“ˆ <b>ØªØ­Ù„ÛŒÙ„ Ù‚ÛŒÙ ØªØ¨Ø¯ÛŒÙ„</b>\n\nÙ‡Ù†ÙˆØ² Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø«Ø¨Øª Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."

        lines = []
        lines.append("ğŸ“ˆ <b>ØªØ­Ù„ÛŒÙ„ Ù‚ÛŒÙ ØªØ¨Ø¯ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†</b>\n")
        lines.append(f"1ï¸âƒ£ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¬Ø¯ÛŒØ¯ (Ø´Ø±ÙˆØ¹ /start): <b>{started}</b> Ù†ÙØ±")
        lines.append("        â†“")
        drop_1 = max(0, started - attempted)
        drop_1_pct = round((drop_1 / started) * 100, 1) if started > 0 else 0
        lines.append(f"2ï¸âƒ£ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¹Ø¶ÙˆÛŒØª: <b>{attempted}</b> Ù†ÙØ± (-{drop_1_pct}%)")
        if attempted > 0:
            lines.append("        â†“")
            drop_2 = max(0, attempted - completed)
            drop_2_pct = round((drop_2 / attempted) * 100, 1) if attempted > 0 else 0
            lines.append(f"3ï¸âƒ£ Ø¹Ø¶ÙˆÛŒØª ØªØ§ÛŒÛŒØ¯ Ø´Ø¯: <b>{completed}</b> Ù†ÙØ± (-{drop_2_pct}%)\n")
            conversion = round((completed / started) * 100, 1)
            lines.append(f"âœ… <b>Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ú©Ù„ÛŒ:</b> {conversion}%")
            lines.append(f"âŒ <b>Ù†Ø±Ø® Ø±ÛŒØ²Ø´ Ú©Ù„ÛŒ:</b> {100 - conversion}%")

        return "\n".join(lines)

    def export_to_csv(self, export_type: str = "all") -> list:
        """Export Ø¢Ù…Ø§Ø± Ø¨Ù‡ CSV: channels | users | daily | all. Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§."""
        files_created = []
        try:
            import csv, os
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            export_dir = "exports"
            os.makedirs(export_dir, exist_ok=True)

            with self._get_connection() as conn:
                cursor = conn.cursor()

                if export_type in ("channels", "all"):
                    cursor.execute(
                        "SELECT channel_id, title, url, status, total_joins, total_join_attempts, conversion_rate, added_at, removed_at FROM analytics_channels ORDER BY added_at DESC"
                    )
                    rows = cursor.fetchall()
                    filename = os.path.join(export_dir, f"channels_{ts}.csv")
                    with open(filename, "w", newline="", encoding="utf-8-sig") as f:
                        writer = csv.writer(f)
                        writer.writerow([
                            "Channel ID", "Title", "URL", "Status", "Total Joins",
                            "Total Attempts", "Conversion Rate", "Added At", "Removed At"
                        ])
                        for r in rows:
                            writer.writerow([
                                r['channel_id'], r['title'], r['url'], r['status'],
                                r['total_joins'], r['total_join_attempts'], r['conversion_rate'],
                                r['added_at'], r['removed_at']
                            ])
                    files_created.append(filename)

                if export_type in ("users", "all"):
                    cursor.execute(
                        "SELECT user_id, first_seen, completed, join_attempts FROM analytics_users ORDER BY first_seen DESC"
                    )
                    rows = cursor.fetchall()
                    filename = os.path.join(export_dir, f"users_{ts}.csv")
                    with open(filename, "w", newline="", encoding="utf-8-sig") as f:
                        writer = csv.writer(f)
                        writer.writerow(["User ID", "First Seen", "Completed", "Join Attempts"])
                        for r in rows:
                            writer.writerow([r['user_id'], r['first_seen'], r['completed'], r['join_attempts']])
                    files_created.append(filename)

                if export_type in ("daily", "all"):
                    cursor.execute(
                        "SELECT date, new_users, successful_joins, failed_joins, total_attempts, conversion_rate FROM analytics_daily_stats ORDER BY date DESC"
                    )
                    rows = cursor.fetchall()
                    filename = os.path.join(export_dir, f"daily_stats_{ts}.csv")
                    with open(filename, "w", newline="", encoding="utf-8-sig") as f:
                        writer = csv.writer(f)
                        writer.writerow([
                            "Date", "New Users", "Successful Joins", "Failed Joins", "Total Attempts", "Conversion Rate"
                        ])
                        for r in rows:
                            writer.writerow([
                                r['date'], r['new_users'], r['successful_joins'], r['failed_joins'], r['total_attempts'], r['conversion_rate']
                            ])
                    files_created.append(filename)

                cursor.close()

        except Exception as e:
            logger.error(f"[Analytics] Error exporting to CSV: {e}")
            return []

        return files_created

    def generate_period_report(self, start_date: str = None, end_date: str = None) -> str:
        """Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø¬Ø¯ÙˆÙ„ analytics_daily_stats"""
        try:
            from datetime import datetime as _dt, timedelta as _td
            if not end_date:
                end_date = _dt.now().strftime("%Y-%m-%d")
            if not start_date:
                start_date = (_dt.now() - _td(days=7)).strftime("%Y-%m-%d")

            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    SELECT 
                        COALESCE(SUM(new_users),0) AS total_new_users, 
                        COALESCE(SUM(successful_joins),0) AS total_successful, 
                        COALESCE(SUM(total_attempts),0) AS total_attempts, 
                        COUNT(*) AS days_with_data
                    FROM analytics_daily_stats
                    WHERE date BETWEEN %s AND %s
                    """,
                    (start_date, end_date)
                )
                row = cursor.fetchone()
                cursor.close()

            total_new_users = int(row.get('total_new_users') or 0) if row else 0
            total_successful = int(row.get('total_successful') or 0) if row else 0
            total_attempts = int(row.get('total_attempts') or 0) if row else 0
            days_with_data = int(row.get('days_with_data') or 0) if row else 0
            lines = []
            lines.append("ğŸ“Š <b>Ú¯Ø²Ø§Ø±Ø´ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ</b>")
            lines.append(f"ğŸ“… Ø§Ø² {start_date} ØªØ§ {end_date}\n")

            if days_with_data == 0:
                lines.append("âš ï¸ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
                return "\n".join(lines)

            lines.append(f"ğŸ‘¥ <b>Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¬Ø¯ÛŒØ¯:</b> {total_new_users} Ù†ÙØ±")
            lines.append(f"âœ… <b>Ø¹Ø¶ÙˆÛŒØª Ù…ÙˆÙÙ‚:</b> {total_successful} Ù†ÙØ±")
            lines.append(f"ğŸ”„ <b>Ú©Ù„ ØªÙ„Ø§Ø´â€ŒÙ‡Ø§:</b> {total_attempts} Ø¨Ø§Ø±")

            avg_users = round(total_new_users / days_with_data, 1)
            avg_success = round(total_successful / days_with_data, 1)
            lines.append("\nğŸ“ˆ <b>Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø±ÙˆØ²Ø§Ù†Ù‡:</b>")
            lines.append(f"   â€¢ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¬Ø¯ÛŒØ¯: {avg_users} Ù†ÙØ±")
            lines.append(f"   â€¢ Ø¹Ø¶ÙˆÛŒØª Ù…ÙˆÙÙ‚: {avg_success} Ù†ÙØ±")

            if total_attempts > 0:
                period_conv = round((total_successful / total_attempts) * 100, 1)
                lines.append(f"\nâœ… <b>Ù†Ø±Ø® ØªØ¨Ø¯ÛŒÙ„ Ø¯ÙˆØ±Ù‡:</b> {period_conv}%")

            return "\n".join(lines)
        except Exception as e:
            logger.error(f"[Analytics] Error generating period report: {e}")
            return "âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ"
